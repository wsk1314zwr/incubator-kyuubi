<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.apache.kyuubi</groupId>
        <artifactId>integration-tests</artifactId>
        <version>1.8.0</version>
        <relativePath>../pom.xml</relativePath>
    </parent>

    <artifactId>kyuubi-spark-it</artifactId>
    <packaging>jar</packaging>

    <name>Kyuubi Spark It</name>
    <url>https://kyuubi.apache.org/</url>

    <dependencies>
        <dependency>
            <groupId>org.apache.kyuubi</groupId>
            <artifactId>kyuubi-spark-lineage_${scala.binary.version}</artifactId>
            <version>1.8.0</version>
        </dependency>
        <!--添加scala依赖-->
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <version>${scala.version}</version>
        </dependency>
        <!--添加spark core 依赖，此依赖不能放开，否则spark3.4.3控制台就没有日志了 -->
<!--        <dependency>-->
<!--            <groupId>org.apache.spark</groupId>-->
<!--            <artifactId>spark-core_2.12</artifactId>-->
<!--            <version>${spark.version}</version>-->
<!--        </dependency>-->
        <!--添加hadoop 客户端的依赖-->
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>${hadoop.version}</version>
        </dependency>

        <!--spark example jars  开始-->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_2.12</artifactId>
            <version>${spark.version}</version>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_2.12</artifactId>
            <version>${spark.version}</version>
            <!--            <exclusions>-->
            <!--                <exclusion>-->
            <!--                    <artifactId>*</artifactId>-->
            <!--                    <groupId>org.apache.hive</groupId>-->
            <!--                </exclusion>-->
            <!--            </exclusions>-->
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-yarn_2.12</artifactId>
            <version>${spark.version}</version>
        </dependency>

        <dependency>
            <groupId>com.alibaba</groupId>
            <artifactId>fastjson</artifactId>
            <version>1.2.49</version>
        </dependency>

        <!-- 添加Spark AVRO的依赖-->
        <dependency>
            <groupId>com.databricks</groupId>
            <artifactId>spark-avro_2.10</artifactId>
            <version>2.0.1</version>
        </dependency>
    </dependencies>
</project>
